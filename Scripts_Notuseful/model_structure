digraph {
	graph [size="62.699999999999996,62.699999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140199046857328 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	140199046766096 [label=AddmmBackward0]
	140199046765712 -> 140199046766096
	140199047915184 [label="fc.bias
 (10)" fillcolor=lightblue]
	140199047915184 -> 140199046765712
	140199046765712 [label=AccumulateGrad]
	140199046765808 -> 140199046766096
	140199046765808 [label=ViewBackward0]
	140199046765856 -> 140199046765808
	140199046765856 [label=AvgPool2DBackward0]
	140199046765568 -> 140199046765856
	140199046765568 [label=ReluBackward0]
	140199046765472 -> 140199046765568
	140199046765472 [label=AddBackward0]
	140199046765376 -> 140199046765472
	140199046765376 [label=NativeBatchNormBackward0]
	140199046765232 -> 140199046765376
	140199046765232 [label=ConvolutionBackward0]
	140199046764896 -> 140199046765232
	140199046764896 [label=ReluBackward0]
	140199046764752 -> 140199046764896
	140199046764752 [label=NativeBatchNormBackward0]
	140199046764560 -> 140199046764752
	140199046764560 [label=ConvolutionBackward0]
	140199046765424 -> 140199046764560
	140199046765424 [label=ReluBackward0]
	140199046764176 -> 140199046765424
	140199046764176 [label=AddBackward0]
	140199046766192 -> 140199046764176
	140199046766192 [label=NativeBatchNormBackward0]
	140199046766336 -> 140199046766192
	140199046766336 [label=ConvolutionBackward0]
	140199046766528 -> 140199046766336
	140199046766528 [label=ReluBackward0]
	140199046766672 -> 140199046766528
	140199046766672 [label=NativeBatchNormBackward0]
	140199046766768 -> 140199046766672
	140199046766768 [label=ConvolutionBackward0]
	140199046764128 -> 140199046766768
	140199046764128 [label=ReluBackward0]
	140199046767056 -> 140199046764128
	140199046767056 [label=AddBackward0]
	140199046767152 -> 140199046767056
	140199046767152 [label=NativeBatchNormBackward0]
	140199046767296 -> 140199046767152
	140199046767296 [label=ConvolutionBackward0]
	140199046767488 -> 140199046767296
	140199046767488 [label=ReluBackward0]
	140199046767632 -> 140199046767488
	140199046767632 [label=NativeBatchNormBackward0]
	140199046767728 -> 140199046767632
	140199046767728 [label=ConvolutionBackward0]
	140199046767920 -> 140199046767728
	140199046767920 [label=ReluBackward0]
	140199046768064 -> 140199046767920
	140199046768064 [label=AddBackward0]
	140199046768160 -> 140199046768064
	140199046768160 [label=NativeBatchNormBackward0]
	140199046768304 -> 140199046768160
	140199046768304 [label=ConvolutionBackward0]
	140199046768496 -> 140199046768304
	140199046768496 [label=ReluBackward0]
	140199046768640 -> 140199046768496
	140199046768640 [label=NativeBatchNormBackward0]
	140199046768736 -> 140199046768640
	140199046768736 [label=ConvolutionBackward0]
	140199046768112 -> 140199046768736
	140199046768112 [label=ReluBackward0]
	140199046769024 -> 140199046768112
	140199046769024 [label=AddBackward0]
	140199046769120 -> 140199046769024
	140199046769120 [label=NativeBatchNormBackward0]
	140199046769264 -> 140199046769120
	140199046769264 [label=ConvolutionBackward0]
	140199046769456 -> 140199046769264
	140199046769456 [label=ReluBackward0]
	140199046769600 -> 140199046769456
	140199046769600 [label=NativeBatchNormBackward0]
	140199046769696 -> 140199046769600
	140199046769696 [label=ConvolutionBackward0]
	140199046769072 -> 140199046769696
	140199046769072 [label=ReluBackward0]
	140199046769984 -> 140199046769072
	140199046769984 [label=AddBackward0]
	140199046770080 -> 140199046769984
	140199046770080 [label=NativeBatchNormBackward0]
	140199046770224 -> 140199046770080
	140199046770224 [label=ConvolutionBackward0]
	140199046770416 -> 140199046770224
	140199046770416 [label=ReluBackward0]
	140199046770560 -> 140199046770416
	140199046770560 [label=NativeBatchNormBackward0]
	140199046770656 -> 140199046770560
	140199046770656 [label=ConvolutionBackward0]
	140199046770848 -> 140199046770656
	140199046770848 [label=ReluBackward0]
	140199046770992 -> 140199046770848
	140199046770992 [label=AddBackward0]
	140199046771088 -> 140199046770992
	140199046771088 [label=NativeBatchNormBackward0]
	140199046771232 -> 140199046771088
	140199046771232 [label=ConvolutionBackward0]
	140199046771424 -> 140199046771232
	140199046771424 [label=ReluBackward0]
	140199046771568 -> 140199046771424
	140199046771568 [label=NativeBatchNormBackward0]
	140199046771664 -> 140199046771568
	140199046771664 [label=ConvolutionBackward0]
	140199046771040 -> 140199046771664
	140199046771040 [label=ReluBackward0]
	140199046771952 -> 140199046771040
	140199046771952 [label=AddBackward0]
	140199046772048 -> 140199046771952
	140199046772048 [label=NativeBatchNormBackward0]
	140199046772192 -> 140199046772048
	140199046772192 [label=ConvolutionBackward0]
	140199046772384 -> 140199046772192
	140199046772384 [label=ReluBackward0]
	140199046772528 -> 140199046772384
	140199046772528 [label=NativeBatchNormBackward0]
	140199046772624 -> 140199046772528
	140199046772624 [label=ConvolutionBackward0]
	140199046772000 -> 140199046772624
	140199046772000 [label=ReluBackward0]
	140199046772912 -> 140199046772000
	140199046772912 [label=AddBackward0]
	140199046773008 -> 140199046772912
	140199046773008 [label=NativeBatchNormBackward0]
	140199046773152 -> 140199046773008
	140199046773152 [label=ConvolutionBackward0]
	140199046773344 -> 140199046773152
	140199046773344 [label=ReluBackward0]
	140199046773488 -> 140199046773344
	140199046773488 [label=NativeBatchNormBackward0]
	140199046773584 -> 140199046773488
	140199046773584 [label=ConvolutionBackward0]
	140199046772960 -> 140199046773584
	140199046772960 [label=ReluBackward0]
	140199046773872 -> 140199046772960
	140199046773872 [label=NativeBatchNormBackward0]
	140199046773968 -> 140199046773872
	140199046773968 [label=ConvolutionBackward0]
	140199046774160 -> 140199046773968
	140199047591824 [label="conv1.weight
 (16, 3, 3, 3)" fillcolor=lightblue]
	140199047591824 -> 140199046774160
	140199046774160 [label=AccumulateGrad]
	140199046773920 -> 140199046773872
	140199047442768 [label="bn1.weight
 (16)" fillcolor=lightblue]
	140199047442768 -> 140199046773920
	140199046773920 [label=AccumulateGrad]
	140199046773680 -> 140199046773872
	140199047432528 [label="bn1.bias
 (16)" fillcolor=lightblue]
	140199047432528 -> 140199046773680
	140199046773680 [label=AccumulateGrad]
	140199046773776 -> 140199046773584
	140199047593104 [label="layer1.0.conv1.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140199047593104 -> 140199046773776
	140199046773776 [label=AccumulateGrad]
	140199046773536 -> 140199046773488
	140199047589664 [label="layer1.0.bn1.weight
 (16)" fillcolor=lightblue]
	140199047589664 -> 140199046773536
	140199046773536 [label=AccumulateGrad]
	140199046773392 -> 140199046773488
	140199047590064 [label="layer1.0.bn1.bias
 (16)" fillcolor=lightblue]
	140199047590064 -> 140199046773392
	140199046773392 [label=AccumulateGrad]
	140199046773296 -> 140199046773152
	140199047788992 [label="layer1.0.conv2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140199047788992 -> 140199046773296
	140199046773296 [label=AccumulateGrad]
	140199046773104 -> 140199046773008
	140199047789072 [label="layer1.0.bn2.weight
 (16)" fillcolor=lightblue]
	140199047789072 -> 140199046773104
	140199046773104 [label=AccumulateGrad]
	140199046773056 -> 140199046773008
	140199047789152 [label="layer1.0.bn2.bias
 (16)" fillcolor=lightblue]
	140199047789152 -> 140199046773056
	140199046773056 [label=AccumulateGrad]
	140199046772960 -> 140199046772912
	140199046772816 -> 140199046772624
	140199047789472 [label="layer1.1.conv1.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140199047789472 -> 140199046772816
	140199046772816 [label=AccumulateGrad]
	140199046772576 -> 140199046772528
	140199047789552 [label="layer1.1.bn1.weight
 (16)" fillcolor=lightblue]
	140199047789552 -> 140199046772576
	140199046772576 [label=AccumulateGrad]
	140199046772432 -> 140199046772528
	140199047789632 [label="layer1.1.bn1.bias
 (16)" fillcolor=lightblue]
	140199047789632 -> 140199046772432
	140199046772432 [label=AccumulateGrad]
	140199046772336 -> 140199046772192
	140199047790112 [label="layer1.1.conv2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140199047790112 -> 140199046772336
	140199046772336 [label=AccumulateGrad]
	140199046772144 -> 140199046772048
	140199047790192 [label="layer1.1.bn2.weight
 (16)" fillcolor=lightblue]
	140199047790192 -> 140199046772144
	140199046772144 [label=AccumulateGrad]
	140199046772096 -> 140199046772048
	140199047790272 [label="layer1.1.bn2.bias
 (16)" fillcolor=lightblue]
	140199047790272 -> 140199046772096
	140199046772096 [label=AccumulateGrad]
	140199046772000 -> 140199046771952
	140199046771856 -> 140199046771664
	140199047905504 [label="layer1.2.conv1.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140199047905504 -> 140199046771856
	140199046771856 [label=AccumulateGrad]
	140199046771616 -> 140199046771568
	140199047905584 [label="layer1.2.bn1.weight
 (16)" fillcolor=lightblue]
	140199047905584 -> 140199046771616
	140199046771616 [label=AccumulateGrad]
	140199046771472 -> 140199046771568
	140199047905664 [label="layer1.2.bn1.bias
 (16)" fillcolor=lightblue]
	140199047905664 -> 140199046771472
	140199046771472 [label=AccumulateGrad]
	140199046771376 -> 140199046771232
	140199047906144 [label="layer1.2.conv2.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	140199047906144 -> 140199046771376
	140199046771376 [label=AccumulateGrad]
	140199046771184 -> 140199046771088
	140199047906224 [label="layer1.2.bn2.weight
 (16)" fillcolor=lightblue]
	140199047906224 -> 140199046771184
	140199046771184 [label=AccumulateGrad]
	140199046771136 -> 140199046771088
	140199047906304 [label="layer1.2.bn2.bias
 (16)" fillcolor=lightblue]
	140199047906304 -> 140199046771136
	140199046771136 [label=AccumulateGrad]
	140199046771040 -> 140199046770992
	140199046770800 -> 140199046770656
	140199047907104 [label="layer2.0.conv1.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140199047907104 -> 140199046770800
	140199046770800 [label=AccumulateGrad]
	140199046770608 -> 140199046770560
	140199047907184 [label="layer2.0.bn1.weight
 (32)" fillcolor=lightblue]
	140199047907184 -> 140199046770608
	140199046770608 [label=AccumulateGrad]
	140199046770464 -> 140199046770560
	140199047907264 [label="layer2.0.bn1.bias
 (32)" fillcolor=lightblue]
	140199047907264 -> 140199046770464
	140199046770464 [label=AccumulateGrad]
	140199046770368 -> 140199046770224
	140199047907744 [label="layer2.0.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140199047907744 -> 140199046770368
	140199046770368 [label=AccumulateGrad]
	140199046770176 -> 140199046770080
	140199047907824 [label="layer2.0.bn2.weight
 (32)" fillcolor=lightblue]
	140199047907824 -> 140199046770176
	140199046770176 [label=AccumulateGrad]
	140199046770128 -> 140199046770080
	140199047907904 [label="layer2.0.bn2.bias
 (32)" fillcolor=lightblue]
	140199047907904 -> 140199046770128
	140199046770128 [label=AccumulateGrad]
	140199046770032 -> 140199046769984
	140199046770032 [label=NativeBatchNormBackward0]
	140199046770752 -> 140199046770032
	140199046770752 [label=ConvolutionBackward0]
	140199046770848 -> 140199046770752
	140199046770896 -> 140199046770752
	140199047906464 [label="layer2.0.downsample.0.weight
 (32, 16, 1, 1)" fillcolor=lightblue]
	140199047906464 -> 140199046770896
	140199046770896 [label=AccumulateGrad]
	140199046770320 -> 140199046770032
	140199047906624 [label="layer2.0.downsample.1.weight
 (32)" fillcolor=lightblue]
	140199047906624 -> 140199046770320
	140199046770320 [label=AccumulateGrad]
	140199046770272 -> 140199046770032
	140199047906704 [label="layer2.0.downsample.1.bias
 (32)" fillcolor=lightblue]
	140199047906704 -> 140199046770272
	140199046770272 [label=AccumulateGrad]
	140199046769888 -> 140199046769696
	140199047908384 [label="layer2.1.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140199047908384 -> 140199046769888
	140199046769888 [label=AccumulateGrad]
	140199046769648 -> 140199046769600
	140199047908464 [label="layer2.1.bn1.weight
 (32)" fillcolor=lightblue]
	140199047908464 -> 140199046769648
	140199046769648 [label=AccumulateGrad]
	140199046769504 -> 140199046769600
	140199047908544 [label="layer2.1.bn1.bias
 (32)" fillcolor=lightblue]
	140199047908544 -> 140199046769504
	140199046769504 [label=AccumulateGrad]
	140199046769408 -> 140199046769264
	140199047909024 [label="layer2.1.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140199047909024 -> 140199046769408
	140199046769408 [label=AccumulateGrad]
	140199046769216 -> 140199046769120
	140199047909104 [label="layer2.1.bn2.weight
 (32)" fillcolor=lightblue]
	140199047909104 -> 140199046769216
	140199046769216 [label=AccumulateGrad]
	140199046769168 -> 140199046769120
	140199047909184 [label="layer2.1.bn2.bias
 (32)" fillcolor=lightblue]
	140199047909184 -> 140199046769168
	140199046769168 [label=AccumulateGrad]
	140199046769072 -> 140199046769024
	140199046768928 -> 140199046768736
	140199047909664 [label="layer2.2.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140199047909664 -> 140199046768928
	140199046768928 [label=AccumulateGrad]
	140199046768688 -> 140199046768640
	140199047909744 [label="layer2.2.bn1.weight
 (32)" fillcolor=lightblue]
	140199047909744 -> 140199046768688
	140199046768688 [label=AccumulateGrad]
	140199046768544 -> 140199046768640
	140199047909824 [label="layer2.2.bn1.bias
 (32)" fillcolor=lightblue]
	140199047909824 -> 140199046768544
	140199046768544 [label=AccumulateGrad]
	140199046768448 -> 140199046768304
	140199047910304 [label="layer2.2.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140199047910304 -> 140199046768448
	140199046768448 [label=AccumulateGrad]
	140199046768256 -> 140199046768160
	140199047910384 [label="layer2.2.bn2.weight
 (32)" fillcolor=lightblue]
	140199047910384 -> 140199046768256
	140199046768256 [label=AccumulateGrad]
	140199046768208 -> 140199046768160
	140199047910464 [label="layer2.2.bn2.bias
 (32)" fillcolor=lightblue]
	140199047910464 -> 140199046768208
	140199046768208 [label=AccumulateGrad]
	140199046768112 -> 140199046768064
	140199046767872 -> 140199046767728
	140199047911504 [label="layer3.0.conv1.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140199047911504 -> 140199046767872
	140199046767872 [label=AccumulateGrad]
	140199046767680 -> 140199046767632
	140199047911584 [label="layer3.0.bn1.weight
 (64)" fillcolor=lightblue]
	140199047911584 -> 140199046767680
	140199046767680 [label=AccumulateGrad]
	140199046767536 -> 140199046767632
	140199047911664 [label="layer3.0.bn1.bias
 (64)" fillcolor=lightblue]
	140199047911664 -> 140199046767536
	140199046767536 [label=AccumulateGrad]
	140199046767440 -> 140199046767296
	140199047912144 [label="layer3.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140199047912144 -> 140199046767440
	140199046767440 [label=AccumulateGrad]
	140199046767248 -> 140199046767152
	140199047912224 [label="layer3.0.bn2.weight
 (64)" fillcolor=lightblue]
	140199047912224 -> 140199046767248
	140199046767248 [label=AccumulateGrad]
	140199046767200 -> 140199046767152
	140199047912304 [label="layer3.0.bn2.bias
 (64)" fillcolor=lightblue]
	140199047912304 -> 140199046767200
	140199046767200 [label=AccumulateGrad]
	140199046767104 -> 140199046767056
	140199046767104 [label=NativeBatchNormBackward0]
	140199046767824 -> 140199046767104
	140199046767824 [label=ConvolutionBackward0]
	140199046767920 -> 140199046767824
	140199046767968 -> 140199046767824
	140199047910864 [label="layer3.0.downsample.0.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	140199047910864 -> 140199046767968
	140199046767968 [label=AccumulateGrad]
	140199046767392 -> 140199046767104
	140199047910944 [label="layer3.0.downsample.1.weight
 (64)" fillcolor=lightblue]
	140199047910944 -> 140199046767392
	140199046767392 [label=AccumulateGrad]
	140199046767344 -> 140199046767104
	140199047911024 [label="layer3.0.downsample.1.bias
 (64)" fillcolor=lightblue]
	140199047911024 -> 140199046767344
	140199046767344 [label=AccumulateGrad]
	140199046766960 -> 140199046766768
	140199047912784 [label="layer3.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140199047912784 -> 140199046766960
	140199046766960 [label=AccumulateGrad]
	140199046766720 -> 140199046766672
	140199047912864 [label="layer3.1.bn1.weight
 (64)" fillcolor=lightblue]
	140199047912864 -> 140199046766720
	140199046766720 [label=AccumulateGrad]
	140199046766576 -> 140199046766672
	140199047912944 [label="layer3.1.bn1.bias
 (64)" fillcolor=lightblue]
	140199047912944 -> 140199046766576
	140199046766576 [label=AccumulateGrad]
	140199046766480 -> 140199046766336
	140199047913344 [label="layer3.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140199047913344 -> 140199046766480
	140199046766480 [label=AccumulateGrad]
	140199046766288 -> 140199046766192
	140199047913424 [label="layer3.1.bn2.weight
 (64)" fillcolor=lightblue]
	140199047913424 -> 140199046766288
	140199046766288 [label=AccumulateGrad]
	140199046766240 -> 140199046766192
	140199047913504 [label="layer3.1.bn2.bias
 (64)" fillcolor=lightblue]
	140199047913504 -> 140199046766240
	140199046766240 [label=AccumulateGrad]
	140199046764128 -> 140199046764176
	140199046764320 -> 140199046764560
	140199047913984 [label="layer3.2.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140199047913984 -> 140199046764320
	140199046764320 [label=AccumulateGrad]
	140199046764704 -> 140199046764752
	140199047914064 [label="layer3.2.bn1.weight
 (64)" fillcolor=lightblue]
	140199047914064 -> 140199046764704
	140199046764704 [label=AccumulateGrad]
	140199046764848 -> 140199046764752
	140199047914144 [label="layer3.2.bn1.bias
 (64)" fillcolor=lightblue]
	140199047914144 -> 140199046764848
	140199046764848 [label=AccumulateGrad]
	140199046764944 -> 140199046765232
	140199047914624 [label="layer3.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	140199047914624 -> 140199046764944
	140199046764944 [label=AccumulateGrad]
	140199046765280 -> 140199046765376
	140199047914704 [label="layer3.2.bn2.weight
 (64)" fillcolor=lightblue]
	140199047914704 -> 140199046765280
	140199046765280 [label=AccumulateGrad]
	140199046765328 -> 140199046765376
	140199047914784 [label="layer3.2.bn2.bias
 (64)" fillcolor=lightblue]
	140199047914784 -> 140199046765328
	140199046765328 [label=AccumulateGrad]
	140199046765424 -> 140199046765472
	140199046765760 -> 140199046766096
	140199046765760 [label=TBackward0]
	140199046765520 -> 140199046765760
	140199047915104 [label="fc.weight
 (10, 64)" fillcolor=lightblue]
	140199047915104 -> 140199046765520
	140199046765520 [label=AccumulateGrad]
	140199046766096 -> 140199046857328
}
